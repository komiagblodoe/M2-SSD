{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4 - exercice 2 : compromis performance / sparsité - pénalités Lasso, Ridge et Elastic-Net\n",
    "\n",
    "Dans cet exercice nous allons illustrer le compromis entre **performances de prédiction** et **interprétabilité du modèle** que l'on observe fréquemment quand on applique les pénalités Lasso et Ridge à des données de haute dimension (et corrélées) : le Lasso permettant d'obtenir un modèle interprétable, mais la pénalité ridge offrant souvent de meilleures performances de prédiction. Nous illustrerons également que la pénalité elastic-net peut s'avérer intéressante dans ce contexte.\n",
    "\n",
    "Pour cela nous travaillerons sur le jeu de données **Golub**, un jeu de données fondateur pour l'analyse de données de puces à ADN pour l'oncologie, dont on trouve un descriptif [ici](https://web.stanford.edu/~hastie/CASI_files/DATA/leukemia.html).\n",
    "Le jeu de données est stocké dans deux fichiers texte **X.txt** et **y.txt** contenant respectivement les observations (72 échantillons en dimension 3571) et les réponses associées (codées ici en 0/1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1. Charger le jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic imports #\n",
    "#-----------------#\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. Visualiser les chemins de régularisation des modèles Lasso et Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3. Réaliser une expérience de validation croisée en utilisant la fonction *cvglmnet()* et afficher les résultats avec la fonction *cvglmnetPlot()*. A quoi correspondent les deux droites verticales représentées par des pointillés bleus ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. Afin de mieux interpréter les résulats, représenter sur une même figure l'évolution des performances de validation croisée obtenue par les deux modèles  quand le paramètre de régularisation varie. Quel modèle offre les meilleures performances ?\n",
    "* contrairement aux figures générées par **cvglmnetplot()** on se contentera de représenter le taux de bonne classification (ou d'erreur) moyen par fold, que l'on trouve dans le champ $\\texttt{cvm}$ du dictionnaire renvoyé par la fonction **cvglmnet()** (e.g., $\\texttt{cvfit['cvm']}$).\n",
    "* on se contentera de représenter l'évolution des performances en fonction de 1...100 (le nombre de valeurs de $\\lambda$ considérées par défaut)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5. Reproduire cette analyse en considérant une penalité elastic-net afin de considérer un compromis entre Lasso et Ridge. Commenter les résultats.\n",
    "* Il suffit pour cela de modifier le paramètre $\\alpha$ de la fonction **cvglmnet()** et de le faire varier entre 0 (Ridge) et 1 (Lasso - valeur par défaut).\n",
    "* On pourra par exemple considérer une grille définie par pas de 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6. Enfin, dresser un bilan des résultats obtenus en représentant  l'évolution (1) des meilleures performances de validation croisée et (2) du nombre de variables sélectionnées, en fonction de $\\alpha$. Commenter les résultats. Quelle valeur de $\\alpha$ retiendriez-vous ? Comparer le chemin de régularisation correspondant à celui du Lasso.\n",
    "* Pour chaque modèle on retiendra la valeur $\\texttt{lambda_1se}$ proposée par la fonction **cvglmnet()** comme \"meilleur\" paramètre de régularisation.\n",
    "* NB : le champ $\\texttt{nzero}$ de l'objet renvoyé par **cvglmnet()** donne le nombre de coefficients non-nuls pour chaque valeur de $\\lambda$ considérée (l'ensemble de ces valeurs étant stockées dans le champ $\\texttt{lambdau}$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
