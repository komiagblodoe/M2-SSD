{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4 - exercice 3 : glmnet & digits\n",
    "\n",
    "Dans cet exercice nous allons illustrer l'utilisation de **glmnet** et des méthodes pénalisés parcimonieuses pour la classification mutliclasse.\n",
    "\n",
    "Pour cela nous travaillerons sur le jeu de données **ZIP** que l'on peut télécharger [ici](https://web.stanford.edu/~hastie/ElemStatLearn/data.html). \n",
    "Comme les jeu **digits** et **MNIST**, ce jeu de données contient des imagettes de caractères manuscrits (des chiffres entre 0 et 1), mais avec une taille intermédiaire. Les images sont en effet de taille 16x16 (au lieu de 8x8 ou 28x28), ce qui réduit le temps nécessaire pour réaliser les analyses.\n",
    "\n",
    "Le jeu de données se constitue d'un ensemble d'apprentissage et d'un ensemble de test, stockés dans les fichiers **zip.train** et **zip.test**. Chaque ligne de ces fichiers contient une instance et contient un chiffre entre 0 et 9 dans la 1ère colonne donnant la catégorie, puis les 256 valeurs définissant l'image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1. Charger le jeu de données et représenter quelques images avec le code ci-dessous.\n",
    "* NB: pour le TP on réduira même la taille du jeu d'apprentissage par 2 pour que l'exécution soit plus rapide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic imports #\n",
    "#-----------------#\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data #\n",
    "#--------------------#\n",
    "data_train = np.genfromtxt('datasets/zip-database/zip.train')\n",
    "y_train = data_train[:,0]\n",
    "X_train = data_train[:,1:]\n",
    "# read test data #\n",
    "#----------------#\n",
    "data_test = np.genfromtxt('datasets/zip-database/zip.test')\n",
    "y_test = data_test[:,0]\n",
    "X_test = data_test[:,1:]\n",
    "print('size of training data = %d x %d' % (X_train.shape[0],X_train.shape[1]))\n",
    "print('size of test data = %d x %d' % (X_test.shape[0],X_test.shape[1]))\n",
    "# show a few figures #\n",
    "#--------------------#\n",
    "# pick samples\n",
    "ind_sple = np.random.choice(len(y_train), size = 8*8, replace = False)\n",
    "# init plot\n",
    "plt.figure(figsize=(6,6))\n",
    "# plot images\n",
    "plt_cptr=0\n",
    "for i in range(8*8):\n",
    "    plt_cptr = plt_cptr+1\n",
    "    plt.subplot(8,8,plt_cptr)\n",
    "    plt.imshow(np.reshape(X_train[ind_sple[i],:],(16,16)), cmap='binary')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "##### REDUCE SIZE OF TRAINING DATASET ######\n",
    "############################################\n",
    "ind_sple = np.random.choice(len(y_train), size = 3500, replace = False)\n",
    "X_train = X_train[ind_sple,:]\n",
    "y_train = y_train[ind_sple]\n",
    "############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. Reproduire l'expérience réalisée dans l'expercice 4 du TP2 visant à reconnaître le $0$ des autres chiffres par un modèle \"Random Forest\" avec le code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a 0-vs-other variable #\n",
    "#------------------------------#\n",
    "# for train\n",
    "y_train_0 = np.zeros(y_train.shape)\n",
    "y_train_0[y_train == 0] = 1\n",
    "# for test\n",
    "y_test_0 = np.zeros(y_test.shape)\n",
    "y_test_0[y_test == 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit random forest model #\n",
    "#-------------------------#\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "# instantiate model\n",
    "rf = RandomForestClassifier(n_estimators = 500)\n",
    "# learn model\n",
    "rf.fit(X_train, y_train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model #\n",
    "#----------------#\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show variable importance #\n",
    "#--------------------------#\n",
    "var_imp = rf.feature_importances_\n",
    "var_imp_mat = np.reshape(var_imp, (16,16))\n",
    "plt.imshow(var_imp_mat, cmap ='binary')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3. Effectuer la même analyse en considérant un modèle de régression logistique pénalisé par une norme $L_1$ (lasso), grâce au package *glmnet_python*.\n",
    "* on optimisera le paramètre de régularisation grâce à la fonction **cvglmnet**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glmnet_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. Considérer à présent le problème de classification multiclasse en utilisant un modèle multinomial. L'objectif principal étant de visualiser et comparer les modèles obtenus par différentes pénalités, on appliquera par souci de temps la procédure suivante : \n",
    "1. construire globalement le modèle (i.e., sans optimiser le paramêtre de régularisation) via la fonction **glmnet()** (en utilisant l'option $\\texttt{family='multinomial'}$\n",
    "2. évaluer ses performances **sur les jeux d'apprentissage et de test** via la fonction **glmnetPredict()**\n",
    "3. représenter les performances obtenues le long du chemin de régularisation, **sur les jeux d'apprentissage et de test**.\n",
    "4. représenter les modèles obtenus pour une \"bonne\" valeur de lambda : une valeur permettant d'obtenir de bonnes performances de test, tout en restant relativement parcimonieux. La ~40ème valeur de la grille obtenue par défaut devrait être un bon compromis.\n",
    "### (bien entendu, la bonne manière de faire consisterait à optimiser le paramètre par validation croisée comme précédemment, et vous êtes tout à fait encouragés à réaliser cette analyse \"pour de vrai\" chez vous.)\n",
    "\n",
    "## Les modèles obtenus sont-ils toujours interprétables ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5. De la même manière, considérer le modèle multinomial pénalisé en norme $L_2$ (ridge) et représenter les modèles obtenus. Sont-ils plus interprétables ?\n",
    "* là aussi, on se contentera de construire le modèle global, d'évaluer les performances train/test et de choisir une valeur de lambda\n",
    "* la ~80ème valeur de la grille obtenue par défaut devrait être un bon compromis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6. Réaliser la même analyse pour le modèle multinomial \"groupé\", i.e., pénalisé en group-lasso.\n",
    "* là aussi, on se contentera de construire le modèle global, d'évaluer les performances train/test et de choisir une valeur de lambda\n",
    "* la ~40ème valeur de la grille obtenue par défaut devrait être un bon compromis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7. Enfin, visualiser les matrices de coefficients retenues, et compter le nombre total de variables retenues dans au moins un des modèles.\n",
    "* on conservera les valeurs de lambda retenues précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
