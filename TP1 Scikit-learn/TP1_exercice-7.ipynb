{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1 - exercice 7 : compromis biais/variance & régression polynomiale\n",
    "\n",
    "Dans cet exercice nous allons illuster le compromis biais/variance dans le cadre de la régression polynomiale.\n",
    "\n",
    "Pour cela nous allons apprendre à manipuler : \n",
    "1. les deux modules de scikit-learn à la base des régression polynomiales : les classes **LinearRegresion** et **PolynomialFeatures** que nous allons combiner dans un \"pipeline\" global grace au module **Pipeline** \n",
    "2. la fonction **validation_curve** permettant de construire les \"courbes de validation\" illustrant le compromis biais/variance que l'on observe quand la complexité du modèle (ici le degré du polynome) varie.\n",
    "\n",
    "Cet exercice est tiré du livre [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) de Jake VanderPlas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1. Générer un jeu de données de taille $N=40$ avec la fonction *make_data* ci-dessous et le représenter. \n",
    "\n",
    "* le paramètre *sig* contrôle le niveau de bruit à considérer lors de la génération des données : le laisser à 1.\n",
    "* idem pour le paramètre *rseed* qui sert à bloquer le générateur de nombre aléatoire (et donc rendre la fonction reproductible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generic imports #\n",
    "#-----------------#\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data generation function #\n",
    "#--------------------------#\n",
    "def make_data(N, sig = 1.0, rseed = 1):\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    x = rng.rand(N, 1)\n",
    "    x = x**2\n",
    "    y = 10 - 1./(x.ravel()+0.1)\n",
    "    y+= sig * rng.randn(N)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. Implémenter un pipeline combinant (i) transformation polynomiale des données et (ii) régression linéaire.\n",
    "\n",
    "* la transformation polynomiale est implémentée par la classe **PolynomialFeatures** du module *preprocessing*.\n",
    "* la régression linéaire est implémentée par la classe **LinearRegression** du module *linear_model*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3. Construire un modèle  de régression polynomiale à partir du jeu de données généré précédemment pour des degrés $d \\in \\{1,2,3,5,10\\}$. Représenter sur un même graphique les modèles obtenus pour $x \\in [0,1]$.\n",
    "\n",
    "* pour cela considérer la grille de valeur donnée par le code ci-dessous.\n",
    "* pour évaluer les différentes valeurs de $d$, on pourra par exemple réaliser une boucle et utiliser la fonction **set_params()** de la classe *Pipeline* pour modifier le degré à chaque itération."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid = np.linspace(0,1,1000)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. Utiliser la fonction [**validation_curve**](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html) du module *model_selection* pour construire une courbe de validation pour des degrés de polynome $d \\in \\{1,20\\}$ et représenter les résultats obtenus. Comment  les interprèter en terme de compromis biais/variance et de sur-/sous-apprentissage ? Quel degré de polynome semble réaliser le meilleur compromis ?\n",
    "\n",
    "* une courbe de validation compare les performances du modèle sur les données d'apprentissage et sur des données de test lorsque la complexité du modèle augmente, en procédant par validation croisée. En comparant les performances d'apprentissage et de validation, on peut juger si le modèle sous-apprend (*underfitting*) ou sur-apprend (*overfitting*). Se référer à [cette page](http://scikit-learn.org/stable/modules/learning_curve.html) pour davantage de précisions et un exemple de mise en oeuvre.\n",
    "* la fonction **validation_curve()** fournit en sortie les performances obtenues pour chaque valeur du paramètre et pour chacune des folds de validation croisée. Commencer par tracer la performance moyenne par fold, puis inclure une barre d'erreur de +1/-1 écart type (via par exemple la fonction [**fill_between**](https://matplotlib.org/examples/pylab_examples/fill_between_demo.html) du package MatplotLib.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5. Tracer la même courbe de validation en considérant un jeu de données de taille $N=120$. Comment interpréter ces résultats ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
