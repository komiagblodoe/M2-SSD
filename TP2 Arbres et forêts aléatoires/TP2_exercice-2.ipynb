{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TP2 - exercice 2 : arbres de régression, sur-apprentissage et régularisation.\n",
    "\n",
    "Dans cet exercice nous allons apprendre à manipuler la classe **DecisionTreeRegressor** du module **tree** qui permet de constuire des modèles de régression par la méthode des arbres de décision. \n",
    "\n",
    "Pour cela nous travaillerons sur un exemple artificiel, tiré du livre [hands on machine learning with scikit-learn and tensorflow](http://shop.oreilly.com/product/0636920052289.do), mettant en jeu une fonction quadratique.\n",
    "\n",
    "Nous verrons comment se manifeste le problème du sur-apprentissage dans ces modèles et comment jouer sur certains hyperparamètres pour le contrôler.\n",
    "\n",
    "Nous reviendrons enfin sur les outils fournis par scikit-learn (et notamment la classe **GridSearchCV**) pour optimiser ces hyperparamètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1. Générer un jeu de données avec le code ci-dessous et le représenter. Quelle fonction va t'on chercher à estimer ?\n",
    "* On laissera les paramètres contrôlant la taille du jeu de données ($n$) et le niveau de bruit ($\\sigma$) à leurs valeurs par défaut.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generic imports #\n",
    "#-----------------#\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_dataset(m = 200, sig = 0.1, seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    # generate x randomly on [0,1]\n",
    "    X = np.random.rand(m,1)\n",
    "    # generate \"true\" y\n",
    "    y = 4 * (X-0.5)** 2\n",
    "    # add noise\n",
    "    y = y + sig*np.random.randn(m, 1)\n",
    "    # return\n",
    "    return X, y\n",
    "\n",
    "X, y  = generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. Construire un modèle de régression en utilisant la classe *DecisionTreeRegressor* du module *tree* en utilisant ses hyperparamètres par défaut. Visualiser la droite de régression obtenue. Qu'observez-vous ? Pourquoi ? \n",
    "* Rappel: pour apprendre/construire un modèle dans scikit-learn il faut : \n",
    "    1. l'instancier via le constructeur de la classe correspondante (en lui spécifiant la valeur des hyperparamètres, si besoin)\n",
    "    2. appeler la méthode **fit** avec les données d'apprentissage $(X,y)$ en argument\n",
    "* Pour représenter la fonction de régression, on l'évaluera (via la fonction **predict**) sur une grille de points régulièrement espacés entre 0 et 1 que l'on peut obtenir avec le **code ci-dessous**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate grid of input values on [0,1]\n",
    "xgrid = np.linspace(0, 1, 500).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3. Construire et visualiser les modèle de régression que  l'on obtient en fixant le paramètre *max_depth* de l'objet *DecisionTreeRegressor* à 2, 3, 4 et 5. Comment interpréter ces résultats ? Quel modèle vous semble le plus adapté ? Est-ce facile de trancher ?\n",
    "* pour une meilleure lisibilité on pourra représenter les différents modèles sur différentes figures, qu'on pourra néanmoins regrouper sur un même graphique par l'utilisation de la fonction **subplot** de *MatplotLib*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. Appliquer la même procédure en contrôlant cette fois le paramètre \"min_samples_leaf\", que l'on prendra dans $\\{ 5, 10, 25, 50 \\}$. La qualité des modèle semble t'elle être plus satisfaisante ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5. Appliquer une procédure de validation croisée pour objectiver les observations faites ci-dessus, en vous appuyant sur la classe *GridSearchCV* du module *model_selection* utilisée dans le TP précédent. Pour cela, procéder en deux temps en réaliser : (1) une première optimisation selon le paramètre *max_depth*, puis (2) une seconde optimisation selon le paramètre *min_samples_leaf*. Quel modèle est globalement le plus performant ?\n",
    "* Se référer à l'exercice 3 du TP1 \n",
    "* On rappelle que pour réaliser cette optimisation d'hyperparamètre il faut : \n",
    "    1. instancier le modèle de prédiction (ici l'objet **DecisionTreeRegressor**, en laissant les hypeparamètres par défaut)\n",
    "    2. définir la \"grille\" de valeurs du (ou des) hyperparamètres à optimiser. Ici on n'optimisera qu'un paramètre à la fois, il faudra donc définir deux listes de ce type.\n",
    "    3. instancier l'objet **GridSearchCV** à partir du modèle et de la grille de paramètre\n",
    "    4. appeler la méthode **fit** de l'objet **gridSearchCV** à partir des données d'apprentissage.\n",
    "* On rappelle également qu'à l'issue de cette procédure on peut notamment : \n",
    "    1. avoir accès au meilleur modèle via l'attribut **best\\_estimator\\_** de l'objet **GridSearchCV**\n",
    "    2. avoir accès à la meilleure configuration via son attribut **best\\_params\\_**\n",
    "    3. avoir accès au score de validation croisée de cette meilleure configuration via son attribut **best\\_score\\_**\n",
    "    4. avoir accès aux scores obtenus par les différentes configurations via son attribut **cv\\_results\\_** (ce qui permet d'analyser comment évoluent les performances en fonction des hyperparamètres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEP 1 : optimisation according to max_depth ###\n",
    "####################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEP 2 : optimisation according to min_samples_leaf ###\n",
    "###########################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6. Enfin, en vous aidant de la [documentation](http://scikit-learn.org/stable/modules/grid_search.html#grid-search) de GridSearchCV, expliquer les différences entre les deux blocs de code ci-dessous. Utiliser l'un ou l'autre change t'il les conclusions précédentes ?\n",
    "* si la documentation n'est pas suffisamment claire, vous intéresser au champ **cv\\_results\\_['params']** des deux objets *GridSearchCV* (une fois estimés) devrait vous donner la réponse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common part \n",
    "tree_reg = DecisionTreeRegressor()\n",
    "leaf_grid = np.concatenate((np.arange(1,5), np.arange(5,31,5)))\n",
    "depth_grid = np.arange(1,11)\n",
    "# 1st way of defining grid of parameters\n",
    "param_grid_1 = {'min_samples_leaf' : leaf_grid,\n",
    "                'max_depth': depth_grid}\n",
    "# define GridSearchCV model\n",
    "grid_search_1 = GridSearchCV(tree_reg, param_grid_1, cv = 10)\n",
    "# carry out optimization\n",
    "grid_search_1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common part \n",
    "tree_reg = DecisionTreeRegressor()\n",
    "leaf_grid = np.concatenate((np.arange(1,5), np.arange(5,31,5)))\n",
    "depth_grid = np.arange(1,11)\n",
    "# 2nd way of defining grid of parameters\n",
    "param_grid_2 = [\n",
    "    {'min_samples_leaf' : leaf_grid},\n",
    "    {'max_depth': depth_grid}\n",
    "]\n",
    "# define GridSearchCV model\n",
    "grid_search_2 = GridSearchCV(tree_reg, param_grid_2, cv = 10)\n",
    "# carry out optimization\n",
    "grid_search_2.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pring results\n",
    "print(\"GRID_SEARCH_1 : The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid_search_1.best_params_, grid_search_1.best_score_))\n",
    "print(\"GRID_SEARCH_2 : The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid_search_2.best_params_, grid_search_2.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Question 7 - pour aller plus loin. Rejouer ces expériences en réduisant le nombre d'observations pour voir dans quel mesure cela impacte la stabilité des modèles obtenus. De même, générer plusieurs jeux de données d'une même taille mais obtenus en faisant varier la graine du générateur de nombres aléatoires lors de la génération du jeu de données (i.e., le paramètre *seed* de la fonction *generate_dataset*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "### Experiment 1 : same model, vary the number of points ###\n",
    "##############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "### Experiment 2 : same model, same number of points, vary the random seed ###\n",
    "##############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
